"""
AI Engine Module - Content-Filter Resistant
The Third Voice - Works around AI model limitations
Built to handle real human communication
"""

import hashlib
import json
import requests
from enum import Enum
from ..data.models import AIResponse
from ..config.settings import AppConfig
import threading
import time


class MessageType(Enum):
    TRANSFORM = "transform"
    INTERPRET = "interpret"


class RelationshipContext(Enum):
    ROMANTIC = "romantic"
    COPARENTING = "coparenting" 
    WORKPLACE = "workplace"
    FAMILY = "family"
    FRIEND = "friend"
    
    @property
    def emoji(self):
        return {
            "romantic": "üíï", "coparenting": "üë®‚Äçüë©‚Äçüëß‚Äçüë¶", "workplace": "üè¢", 
            "family": "üè†", "friend": "ü§ù"
        }[self.value]
    
    @property 
    def description(self):
        return {
            "romantic": "Partner & intimate relationships", "coparenting": "Raising children together",
            "workplace": "Professional relationships", "family": "Extended family connections", 
            "friend": "Friendships & social bonds"
        }[self.value]


class AIEngine:
    """AI engine that works around content filtering"""
    
    def __init__(self):
        # Try models in order of preference - some are less restrictive
        self.models = [
            {"id": "deepseek/deepseek-chat-v3-0324:free", "name": "DeepSeek Chat v3", "note": "Usually less restrictive"},
            {"id": "deepseek/deepseek-r1-distill-llama-70b:free", "name": "DeepSeek R1 Distill", "note": "Alternative option"},
            {"id": "meta-llama/llama-3.2-3b-instruct:free", "name": "Llama 3.2 3B", "note": "Meta's instruction model"},
            {"id": "qwen/qwen-2.5-7b-instruct:free", "name": "Qwen 2.5 7B", "note": "Alibaba's instruction model"},
            {"id": "google/gemma-2-9b-it:free", "name": "Gemma 2 9B", "note": "Google's instruction model"}
        ]

        # Start background prewarm
        threading.Thread(target=self._prewarm_models, daemon=True).start()

    def _prewarm_models(self):
        """Prewarm all models to reduce first-call latency"""
        print("‚ö° Prewarming AI models in background...")
        for model_info in self.models:
            try:
                self._try_model(model_info, "You are a helper AI.", "Hello. Prewarming model for faster response.")
                time.sleep(0.2)  # small pause to avoid rate limits
            except Exception as e:
                print(f"‚ö†Ô∏è Prewarm failed for {model_info['name']}: {e}")
        print("‚úÖ Prewarming complete.")

    def _get_model_display_name(self, model_id: str) -> str:
        """Get user-friendly model name"""
        for model in self.models:
            if model["id"] == model_id:
                return model["name"]
        return model_id.split("/")[-1].replace(":free", "")
    
    def _sanitize_message(self, message: str) -> str:
        """Lightly sanitize message to avoid content filtering while preserving meaning"""
        sanitized = message.replace("bitch", "[expletive]")
        sanitized = sanitized.replace("vagina", "[inappropriate reference]")
        sanitized = sanitized.replace("deport", "remove from country")
        return sanitized
    
    def _try_model(self, model_info: dict, system_prompt: str, user_prompt: str) -> dict:
        """Try a specific model and return the result"""
        model_id = model_info["id"]
        print(f"ü§ñ Trying model: {model_info['name']} ({model_id})")
        api_key = AppConfig.get_openrouter_api_key()
        if not api_key:
            print("‚ùå ERROR: No OpenRouter API key found!")
            return None
        try:
            response = requests.post(
                f"{AppConfig.OPENROUTER_BASE_URL}/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model_id,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": 1000,
                    "temperature": 0.7
                },
                timeout=30
            )
            print(f"üì° Status: {response.status_code}")
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and result["choices"]:
                    return result
            print(f"‚ùå Model {model_info['name']} failed: Status {response.status_code}")
            print(f"   Error details: {response.text[:300] if response.text else 'No response'}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Network error with {model_info['name']}: {str(e)}")
            return None
        except Exception as e:
            print(f"‚ùå Unexpected error with {model_info['name']}: {str(e)}")
            return None

    def process_message(self, message: str, contact_context: str, message_type: str,
                        contact_id: str, user_id: str, db) -> AIResponse:
        """Process message with multiple model fallbacks"""
        print(f"üéôÔ∏è Processing message: {message[:50]}...")
        used_model_id = None
        used_model_name = None

        # Prepare prompts
        if message_type == MessageType.TRANSFORM.value:
            system_prompt = """You are a communication helper. Rewrite messages to be more constructive and healing while keeping the core meaning. Handle all content professionally.

Respond with JSON:
{"transformed_message": "rewritten message", "healing_score": 7, "sentiment": "positive", "emotional_state": "caring", "explanation": "why this helps"}"""
            
            user_prompts = [
                f'Please rewrite this message to be more constructive: "{message}"',
                f'Please rewrite this message to be more constructive: "{self._sanitize_message(message)}"'
            ]
        else:
            system_prompt = """You are a communication helper. Interpret what someone really means beneath their words, even when they're upset or using strong language. Suggest compassionate responses. Handle all content professionally.

Respond with JSON:
{"transformed_message": "suggested response", "healing_score": 6, "sentiment": "neutral", "emotional_state": "understanding", "explanation": "what they really mean", "subtext": "their deeper feelings", "needs": ["emotional needs"], "warnings": []}"""
            
            user_prompts = [
                f'Help me understand what they really mean and how to respond compassionately: "{message}"',
                f'Help me understand what they really mean and how to respond compassionately: "{self._sanitize_message(message)}"'
            ]

        # Try each model
        for model_info in self.models:
            for user_prompt in user_prompts:
                try:
                    result = self._try_model(model_info, system_prompt, user_prompt)
                    if result:
                        ai_text = result["choices"][0]["message"]["content"]
                        print(f"‚úÖ Got response from {model_info['name']}: {ai_text[:50]}...")
                        used_model_id = model_info["id"]
                        used_model_name = model_info["name"]
                        try:
                            ai_data = json.loads(ai_text)
                        except:
                            start = ai_text.find('{')
                            end = ai_text.rfind('}') + 1
                            if start >= 0 and end > start:
                                ai_data = json.loads(ai_text[start:end])
                            else:
                                continue
                        return AIResponse(
                            transformed_message=ai_data.get("transformed_message", "I understand this is difficult."),
                            healing_score=int(ai_data.get("healing_score", 5)),
                            sentiment=ai_data.get("sentiment", "neutral"),
                            emotional_state=ai_data.get("emotional_state", "understanding"),
                            explanation=ai_data.get("explanation", "Providing support"),
                            subtext=ai_data.get("subtext", ""),
                            needs=ai_data.get("needs", []),
                            warnings=ai_data.get("warnings", []),
                            model_used=used_model_name,
                            model_id=used_model_id
                        )
                except Exception as e:
                    print(f"‚ö†Ô∏è Error with {model_info['name']}: {str(e)}")
                    continue

        # Fallback
        print("üí• All models failed, using intelligent fallback")
        message_lower = message.lower()
        if message_type == MessageType.INTERPRET.value:
            if "deport" in message_lower or "immigration" in message_lower:
                return AIResponse(
                    transformed_message="I can hear how scared and angry you are about the immigration situation. You're dealing with so much uncertainty and betrayal. I'm here for you through all of this - you don't have to face it alone.",
                    healing_score=7, sentiment="neutral", emotional_state="understanding",
                    explanation="Your friend is expressing deep fear about deportation, anger about betrayal, and the stress of legal troubles. They're using dark humor to cope but really need support and understanding.",
                    subtext="Feeling scared, betrayed, and overwhelmed by legal/immigration issues",
                    needs=["safety", "support", "loyalty", "someone who understands", "emotional validation"],
                    model_used="Fallback System",
                    model_id="fallback"
                )
            elif "family" in message_lower and "torn apart" in message_lower:
                return AIResponse(
                    transformed_message="I hear the pain in your words about your family being torn apart. You're right that we've both been through hell in different ways. I see you, I understand your struggle, and I'm grateful you're sharing this with me.",
                    healing_score=6, sentiment="neutral", emotional_state="understanding",
                    explanation="They're sharing deep pain about family separation and life's unfairness, looking for connection with someone who understands similar struggles.",
                    subtext="Feeling isolated and hurt by family separation, seeking understanding from someone who relates",
                    needs=["empathy", "validation", "connection", "shared understanding"],
                    model_used="Fallback System",
                    model_id="fallback"
                )
            else:
                return AIResponse(
                    transformed_message="I can see you're dealing with so much pain and anger right now. Thank you for trusting me with these heavy feelings. I'm here to listen and support you however I can.",
                    healing_score=6, sentiment="neutral", emotional_state="understanding",
                    explanation="They're sharing intense emotions and difficult circumstances, needing someone to witness their pain without judgment.",
                    subtext="Overwhelmed by multiple life challenges and needing emotional support",
                    needs=["validation", "emotional support", "someone to listen"],
                    model_used="Fallback System",
                    model_id="fallback"
                )
        else:
            return AIResponse(
                transformed_message="I'm going through a really tough time and feeling overwhelmed by everything happening. I value our friendship and wanted to share what's on my mind. Can we talk?",
                healing_score=5, sentiment="neutral", emotional_state="caring",
                explanation="Transformed the raw emotions into a request for connection and support",
                model_used="Fallback System",
                model_id="fallback"
            )
