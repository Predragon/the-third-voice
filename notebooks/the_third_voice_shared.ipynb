{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîë Enter your API keys and credentials\n",
    "This cell will save your OpenRouter API key, Supabase URL, and Supabase anon key into `.streamlit/secrets.toml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, os\n",
    "\n",
    "# Prompt user for required keys\n",
    "openrouter_key = getpass.getpass(\"Enter your OpenRouter API key: \")\n",
    "supabase_url = input(\"Enter your Supabase URL: \").strip()\n",
    "supabase_key = getpass.getpass(\"Enter your Supabase anon key: \")\n",
    "\n",
    "# Create the .streamlit directory if it doesn't exist\n",
    "os.makedirs(\".streamlit\", exist_ok=True)\n",
    "\n",
    "# Write secrets.toml in Streamlit format\n",
    "with open(\".streamlit/secrets.toml\", \"w\") as f:\n",
    "    f.write(f\"\"\"[openrouter]\n",
    "api_key = \\\"{openrouter_key}\\\"\n",
    "\n",
    "[supabase]\n",
    "url = \\\"{supabase_url}\\\"\n",
    "key = \\\"{supabase_key}\\\"\n",
    "\n",
    "[MODELS]\n",
    "model1 = \\\"google/gemma-2-9b-it:free\\\"\n",
    "model2 = \\\"deepseek/deepseek-chat-v3-0324:free\\\"\n",
    "model3 = \\\"deepseek/deepseek-r1-distill-llama-70b:free\\\"\n",
    "model4 = \\\"meta-llama/llama-3.2-3b-instruct:free\\\"\n",
    "model5 = \\\"qwen/qwen-2.5-7b-instruct:free\\\"\n",
    "model6 = \\\"microsoft/phi-3-mini-4k-instruct:free\\\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Secrets saved to .streamlit/secrets.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Clone the repo (skip if exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"the-third-voice\"):\n",
    "    !git clone https://github.com/Predragon/the-third-voice.git\n",
    "else:\n",
    "    print(\"üìÇ Repo already exists ‚Äî skipping clone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì• Install dependencies (pinned versions for stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "    streamlit==1.47.2 \\\n",
    "    supabase==2.4.0 \\\n",
    "    requests==2.32.3 \\\n",
    "    python-dateutil==2.9.0.post0 \\\n",
    "    validators==0.22.0 \\\n",
    "    passlib==1.7.4 \\\n",
    "    bcrypt==4.2.0 \\\n",
    "    python-dotenv==1.0.1 \\\n",
    "    loguru==0.7.2 \\\n",
    "    typing-extensions==4.12.2 \\\n",
    "    pandas==2.2.2 \\\n",
    "    numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Import AI engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"the-third-voice\")\n",
    "\n",
    "from src.core.ai_engine import process_message\n",
    "print(\"‚úÖ AI engine imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Run a test prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"Hello, can you help me rewrite this kindly?\"\n",
    "try:\n",
    "    ai_response = process_message(test_input)\n",
    "    print(\"ü§ñ AI Response:\", ai_response)\n",
    "    print(\"\\n\\033[92m‚úÖ The Third Voice AI setup complete! You're ready to go.\\033[0m\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error running test prompt:\", e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "the_third_voice_shared.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
