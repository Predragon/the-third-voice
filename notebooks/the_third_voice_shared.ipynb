# ================================================================
# 🗂 The Third Voice – Setup & Architecture
# ================================================================
from IPython.display import Markdown, display
import os

# Clone repo if not exists
if not os.path.exists("the-third-voice"):
    !git clone https://github.com/Predragon/the-third-voice.git

display(Markdown("## 🗂 The Third Voice – Architecture Overview"))

# Show ASCII diagram (no external file needed)
ascii_diagram = r"""
"""
display(Markdown(ascii_diagram))

display(Markdown("""
**✅ Key Setup Checklist**
- **OpenRouter API Key** – Required for all modes (free from [https://openrouter.ai](https://openrouter.ai)).
- **Supabase URL & Key** – Optional, only if you want to store persistent chat history.
- **Quick Test Mode** – If you skip Supabase setup, chats will work but won't be saved.

> **Tip:** You can always add Supabase later without changing your AI settings.
"""))

# ================================================================
# 🔑 Enter API Keys & Save to .streamlit/secrets.toml
# ================================================================
import getpass, toml

openrouter_key = getpass.getpass("Enter your OpenRouter API key: ")
supabase_url = input("Enter your Supabase URL (leave blank for Quick Test Mode): ").strip()
supabase_key = ""
if supabase_url:
    supabase_key = getpass.getpass("Enter your Supabase anon key: ")

os.makedirs(".streamlit", exist_ok=True)

# Write secrets safely to avoid TOML format errors
secrets_dict = {
    "openrouter": {"api_key": openrouter_key.strip()},
    "supabase": {
        "url": supabase_url.strip(),
        "key": supabase_key.strip()
    },
    "MODELS": {
        "model1": "google/gemma-2-9b-it:free",
        "model2": "deepseek/deepseek-chat-v3-0324:free",
        "model3": "deepseek/deepseek-r1-distill-llama-70b:free",
        "model4": "meta-llama/llama-3.2-3b-instruct:free",
        "model5": "qwen/qwen-2.5-7b-instruct:free",
        "model6": "microsoft/phi-3-mini-4k-instruct:free"
    }
}

with open(".streamlit/secrets.toml", "w") as f:
    toml.dump(secrets_dict, f)

quick_test_mode = not bool(supabase_url)
if quick_test_mode:
    print("⚡ Quick Test Mode enabled (no Supabase, chat history won't be saved)")
else:
    print("✅ Full Mode enabled (Supabase connected)")

# ================================================================
# 📦 Install Dependencies
# ================================================================
!pip install \
    streamlit==1.48.0 \
    supabase==2.4.0 \
    requests==2.32.3 \
    python-dateutil==2.9.0.post0 \
    validators==0.22.0 \
    passlib==1.7.4 \
    bcrypt==4.2.0 \
    python-dotenv==1.0.1 \
    loguru==0.7.2 \
    typing-extensions==4.12.2 \
    pandas==2.2.2 \
    numpy==1.26.4 \
    toml==0.10.2

# ================================================================
# 📚 Import AI Engine
# ================================================================
import sys
sys.path.append("the-third-voice")

try:
    from src.core.ai_engine import process_message
    print("✅ AI engine imported successfully")
except Exception as e:
    print("❌ Error importing AI engine:", e)

# ================================================================
# 🚀 Run Test Prompt
# ================================================================
test_input = "Hello, can you help me rewrite this kindly?"
try:
    # Load model from secrets
    secrets = toml.load(".streamlit/secrets.toml")
    model = secrets["MODELS"]["model1"]

    ai_response = process_message(
        message=test_input,
        model=model,
        user_id="quick_test_user",
        supabase_client=None if quick_test_mode else "supabase_client_placeholder"
    )

    print("🤖 AI Response:", ai_response)
    print("\n\033[92m✅ The Third Voice AI setup complete!\033[0m")
except Exception as e:
    print("❌ Error running test prompt:", e)
