{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Third Voice ‚Äî Colab Quick Start (developer-focused)\n",
    "\n",
    "This notebook boots **The Third Voice** in Colab.\n",
    "\n",
    "Requirements:\n",
    "- **OpenRouter API key** ‚Äî required (free). Used to call models.\n",
    "- **Supabase URL & anon key** ‚Äî optional. Provide for persistent storage (chat history, analytics). If you skip them, the notebook runs in **Quick Test Mode** (stateless, in-memory).\n",
    "\n",
    "Quick flow:\n",
    "1. Enter credentials when prompted. (Supabase fields may be left blank for a quick test.)\n",
    "2. Notebook will clone the repo, install requirements, import your AI engine, and run a small test prompt.\n",
    "\n",
    "Developer note: this notebook assumes the repo's `src/core/ai_engine.py` exposes `process_message(prompt)` or similar. The test will call `process_message(...)` and let your engine pick the model internally. We also show `model2` from `.streamlit/secrets.toml` so the configured DeepSeek model is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "python_version_check"
   },
   "outputs": [],
   "source": [
    "# Ensure Python 3.10 for compatibility (Colab may need a restart after switching)\n",
    "import sys, os\n",
    "if not sys.version.startswith(\"3.10\"):\n",
    "    print(\"‚ö† Python is not 3.10. Attempting to install python3.10 and restart the runtime.\")\n",
    "    # Attempt to install python3.10 (may prompt and restart runtime)\n",
    "    !apt-get update -y\n",
    "    !apt-get install -y python3.10 python3.10-dev python3.10-distutils\n",
    "    !update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 || true\n",
    "    !python3 -m pip install --upgrade pip\n",
    "    print(\"‚ö† Restart the runtime (Runtime -> Restart runtime) then re-run this notebook to continue with Python 3.10.\")\n",
    "    import sys\n",
    "    sys.exit(0)\n",
    "else:\n",
    "    print(f\"‚úÖ Python version OK: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_secrets"
   },
   "outputs": [],
   "source": [
    "# üîë Prompt for credentials (OpenRouter required; Supabase optional)\n",
    "import getpass, os\n",
    "openrouter_key = getpass.getpass(\"Enter your OpenRouter API key (required): \")\n",
    "supabase_url = input(\"Enter your Supabase URL (optional, press Enter to skip): \").strip()\n",
    "supabase_key = getpass.getpass(\"Enter your Supabase anon key (optional, press Enter to skip): \")\n",
    "\n",
    "os.makedirs('.streamlit', exist_ok=True)\n",
    "secrets_content = f'''[openrouter]\n",
    f\"api_key = \\\"{openrouter_key}\\\"\\n\\n\"\n",
    "secrets_content += f\"[supabase]\\nurl = \\\"{supabase_url}\\\"\\nkey = \\\"{supabase_key}\\\"\\n\\n\"\n",
    "secrets_content += \"[MODELS]\\n\"\n",
    "secrets_content += 'model1 = \"google/gemma-2-9b-it:free\"\\n'\n",
    "secrets_content += 'model2 = \"deepseek/deepseek-chat-v3-0324:free\"\\n'\n",
    "secrets_content += 'model3 = \"deepseek/deepseek-r1-distill-llama-70b:free\"\\n'\n",
    "secrets_content += 'model4 = \"meta-llama/llama-3.2-3b-instruct:free\"\\n'\n",
    "secrets_content += 'model5 = \"qwen/qwen-2.5-7b-instruct:free\"\\n'\n",
    "secrets_content += 'model6 = \"microsoft/phi-3-mini-4k-instruct:free\"\\n'\n",
    "\n",
    "with open('.streamlit/secrets.toml', 'w') as f:\n",
    "    f.write(secrets_content)\n",
    "\n",
    "if supabase_url and supabase_key:\n",
    "    print('\\n‚úÖ Supabase credentials provided ‚Äî running in Full App Mode (persistent storage enabled).')\n",
    "else:\n",
    "    print('\\n‚ö† No Supabase credentials provided ‚Äî running in Quick Test Mode (stateless, in-memory).')\n",
    "\n",
    "print('‚úÖ .streamlit/secrets.toml written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_install"
   },
   "outputs": [],
   "source": [
    "# üì¶ Fresh clone + install\n",
    "import os, shutil\n",
    "if os.path.exists('the-third-voice'):\n",
    "    print('Removing existing the-third-voice folder...')\n",
    "    shutil.rmtree('the-third-voice')\n",
    "\n",
    "!git clone https://github.com/Predragon/the-third-voice.git\n",
    "%cd the-third-voice\n",
    "!python3 -m pip install --upgrade pip\n",
    "# Install pinned deps from requirements.txt; editable installs may vary in your repo\n",
    "!pip install -r requirements.txt || true\n",
    "\n",
    "print('\\n‚úÖ Repo cloned and dependency install attempted. If installation failed, inspect the above logs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_ai_engine"
   },
   "outputs": [],
   "source": [
    "# üì• Import AI engine (assumes src/core/ai_engine.py exists and exposes process_message)\n",
    "import importlib, sys, os, toml\n",
    "sys.path.append(os.getcwd())\n",
    "try:\n",
    "    from src.core.ai_engine import process_message\n",
    "    print('‚úÖ process_message imported from src.core.ai_engine')\n",
    "except Exception as e:\n",
    "    print('‚ùå Could not import process_message from src.core.ai_engine:', e)\n",
    "    print('Make sure the repo structure is intact and src/core/ai_engine.py exists.')\n",
    "\n",
    "# Load the saved secrets and show the configured DeepSeek model (model2)\n",
    "secrets = toml.load(os.path.join('..', '.streamlit', 'secrets.toml')) if os.path.exists(os.path.join('..', '.streamlit', 'secrets.toml')) else toml.load('.streamlit/secrets.toml')\n",
    "model2 = secrets.get('MODELS', {}).get('model2', 'model2 not found')\n",
    "print('Configured DeepSeek (model2):', model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deepseek_test"
   },
   "outputs": [],
   "source": [
    "# ü§ñ Run a short test through your app's process_message (let the ai_engine pick the model)\n",
    "test_prompt = \"Hello, can you kindly rewrite this short note for clarity?\"\n",
    "print('\\nüîÑ Running AI test prompt (using the app\\'s model selection)...')\n",
    "try:\n",
    "    # We let the engine pick model internally; if your process_message accepts extra args, adapt as needed.\n",
    "    response = process_message(test_prompt)\n",
    "    print('\\nü§ñ AI Response:\\n')\n",
    "    print(response)\n",
    "    print('\\n‚úÖ Setup complete ‚Äî AI test succeeded')\n",
    "except Exception as e:\n",
    "    print('\\n‚ùå AI test failed with exception:')\n",
    "    print(e)\n",
    "    print('\\nIf this is due to missing Supabase configuration and your ai_engine expects it, either supply Supabase credentials in the earlier cell or modify your ai_engine to support stateless mode.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
