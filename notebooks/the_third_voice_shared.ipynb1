# ===============================================================
# 📜 Instructions — Read this before running
# ===============================================================
# This notebook sets up "The Third Voice" AI environment.
#
# You will need:
#
# 1️⃣ **OpenRouter API Key** (free)
#    - Go to: https://openrouter.ai
#    - Sign up with GitHub, Google, or email
#    - In your dashboard → "API Keys" → "Create Key"
#
# 2️⃣ **Supabase URL & Anon Key** (free)
#    - Go to: https://supabase.com
#    - Sign up and create a new project
#    - In Project Settings → "API" → copy:
#         • `Project URL` → this is your Supabase URL
#         • `anon public` key → this is your anon key
#
#    (If you just want to test the AI without saving messages,
#     you can leave Supabase URL and Key blank.)
#
# After you have these, run each cell in order.
# ===============================================================


# ===============================================================
# 🔑 Step 1 — Enter your API keys and credentials
# ===============================================================
import getpass, os

# Prompt user for required keys
openrouter_key = getpass.getpass("Enter your OpenRouter API key: ")
supabase_url = input("Enter your Supabase URL (or leave blank to skip DB): ").strip()
supabase_key = getpass.getpass("Enter your Supabase anon key (or leave blank to skip DB): ")

# Create the .streamlit directory if it doesn't exist
os.makedirs(".streamlit", exist_ok=True)

# Write secrets.toml in Streamlit format
with open(".streamlit/secrets.toml", "w") as f:
    f.write(f"""[openrouter]
api_key = "{openrouter_key}"

[supabase]
url = "{supabase_url}"
key = "{supabase_key}"

[MODELS]
model1 = "google/gemma-2-9b-it:free"
model2 = "deepseek/deepseek-chat-v3-0324:free"
model3 = "deepseek/deepseek-r1-distill-llama-70b:free"
model4 = "meta-llama/llama-3.2-3b-instruct:free"
model5 = "qwen/qwen-2.5-7b-instruct:free"
model6 = "microsoft/phi-3-mini-4k-instruct:free"
""")

print("✅ Secrets saved to .streamlit/secrets.toml")


# ===============================================================
# 📦 Step 2 — Clone the repo (skip if exists)
# ===============================================================
if not os.path.exists("the-third-voice"):
    !git clone https://github.com/Predragon/the-third-voice.git
else:
    print("📂 Repo already exists — skipping clone.")


# ===============================================================
# 📥 Step 3 — Install dependencies
# ===============================================================
!pip install \
    streamlit==1.48.0 \
    supabase==2.4.0 \
    requests==2.32.3 \
    python-dateutil==2.9.0.post0 \
    validators==0.22.0 \
    passlib==1.7.4 \
    bcrypt==4.2.0 \
    python-dotenv==1.0.1 \
    loguru==0.7.2 \
    typing-extensions==4.12.2 \
    pandas==2.2.2 \
    numpy==1.26.4 \
    toml==0.10.2


# ===============================================================
# 📚 Step 4 — Import AI engine
# ===============================================================
import sys
sys.path.append("the-third-voice")

from src.core.ai_engine import process_message
import toml

print("✅ AI engine imported successfully")


# ===============================================================
# 🚀 Step 5 — Quick Test Mode
# ===============================================================
# Load model from secrets.toml
secrets = toml.load(".streamlit/secrets.toml")
model = secrets["MODELS"]["model1"]

test_input = "Hello, can you help me rewrite this kindly?"

try:
    ai_response = process_message(
        message=test_input,
        model=model,
        user_id="quick_test_user",
        supabase_client=None  # skip DB in Quick Test Mode
    )
    print("\n🤖 AI Response:", ai_response)
    print("\n✅ The Third Voice AI setup complete! You're ready to go.")
except Exception as e:
    print("❌ Error running test prompt:", e)
